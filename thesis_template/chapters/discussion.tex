\chapter{Discussion}\label{chap:discussion}

This sections will validate the results obtained from the experiments and explains some of the challenges faced during the implementation of the experiments, also the other different methods to evaluate a algorithm over a given problem set.

\section{Autosklearn and Tpot comparsion}

First the two libraries are better in their own terms, the individual methodology works efficiently across different datasets unless the dataset is itself not optimal. The performance across the datasets from the fig \ref{fig:performance} tells us that there is no significant difference in there performance excpet for few of the datasets, also from the preference \ref{fig:algorithm} of estimators in both the libraries seem to favour a common estimator which indicates that the search methodology employed meets at a common point for reaching solutions. The main aim of bayesian optimization and genetic algorithms is to reach a solution keeping in check with cost or the threshold available. The two methodologies emphasize on scoring and evaluating the solutions found at each iteration, this would not only give a point of interest in further steps of optimization also it cuts down time. From the series of literature surveys, one common point on algorithm optimization is the hyperparameter configuration, this is the crucial and most important aspect from bayesian and genetic optimization process

There is no universal algorithm which could perform better at any given problem, every algorithm has its parameters tuned in order to achieve the highest score. From the experiments we can say that a ensemble of models and a single pipeline model could perform equally at certain tasks. In order to quantify which library is better at performance from the experiments based on the scores and from only a very thin margin of difference Tpot performed better at classification tasks and Autosklearn performed better at regression tasks only by a small difference. Overall performance of the libraries are very similar. Coming to the usage of the two libraries both of them are built on top of sklearn\cite{scikit-learn} which provides a common development environment to work on. Having hands on experience with sklearn, using both the libraries to setup experiments was commonly executed. This approach of the authors to extend there techniques over a common library should be commendable. Autosklearn with its final outcome does not provide a ready to run script to play around with the model with different data whereas tpot provides a python script of the best selected pipeline with all its configuration for use with other datasets and for further specific tuning. Finally the overall report which can be drawn from this experiments is that based on chosen performance criteria and statistical test there is no clear winner on which is the best library, but from my perspective i would prefer Autosklearn over tpot due to Autosklearn having meta-learing feature implemented and also for the verbosity shown during the execution of the experiments.

\section{Web Interface}

Visual analytics is a great way of gathering information, it allows us to see hidden patterns over the plain data find meaning from the patterns, examine distributions and can come to strong and definitive conclusions from observations. The development of web interface was strongly based on the principles of visual analytic's but how much of it was utilized is the question to be answered. Common user interaction guidelines had been followed to design the layout. One page application gives more focus than multiple web pages, since its a evaluation framework for machine learning all the results has to be in front of the user for efficient analysis we tried as much as possible to keep the look and feel of the interface as simple and fast as possible. The web interface overall provides a simple interface to compare the results from both the libraries, being built specifically to compare the performance of the libraries emphasis is made on detailed analysis of data. The setup and development of the web interface was easier and faster due to  Dash framework's visual analytic abilities and examples showcased. Finally the framework is simple and easy to use and its also interactive with graphs which is a essential part of any evaluation framework.