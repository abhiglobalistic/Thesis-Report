\chapter{Introduction}\label{chap:introduction}


Motivate your research and outline the research gap in this chapter. Why is your thesis relevant and what do you address, what has not been addressed before. 

\textbf{[write about small info on automl methods here]}
Machine learning which is a domain of Artificial Intelligence has come across many developments during the recent years, with the increase in availability of numerous data from different domains such as Medicine, Astronomy, Housing, Wearable Devices, Manufacturing, E-commerce and much more. Several Applications of machine learning include Object recognition, Natural language processing, Speech and handwriting recognition, Recommendation systems and many more. ML nowadays is employed in most of the digital systems, for example the advertisements we come across in our social media pages, product recommendations in online shops based on our purchase history. These systems make use of the previous data which has been generated from our online activity and they build a model out of the data, this model tries to predict our next outcome based on the previous observations which we had made. as for advertising and product recommendations several other domains of data such as wearable devices like smart watches, fitness trackers these devices record your daily walking distances, biking, places you visit. Based on these samples of data the system would assist you in your daily activities and also provide health based recommendations.

Digitization\cite{6147691} process has led to a large increase in data collection, these data samples might not be of any interest to a end user, but these enormous collection of samples hold a variety of patterns which in turn can provide valuable information about a certain entity of interest. By analyzing the data and discovering unknown patterns new ideas could emerge and thus leading to innovation and efficiency.

The data collected from different sources, not only from digitization or human interaction with the digital world are aiding the progress of machine learning techniques and developing new algorithms to further improve the learning process. The process of machine learning is to learn from the data provided and predict something meaningful. The procedure of ML is divided into certain categories such as Supervised, Semi Supervised and unsupervised learning and several others namely Active and reinforcement learning. In order to decide which technique to use we need to first look at the data at hand. As in any machine learning project or task one has to gather the required data at first, for example a data-set consisting of samples of different fruit properties like color, PH,size, season and these properties or features are labelled to there respective fruit name like Apple or orange. Here this is a classification task where the machine learning model will learn from the samples and classify the fruit to which it belongs. Since we have samples and its labels(fruit names) this belongs to Supervised Learning. For unsupervised learning the labels are not defined just the samples containing the features or properties from entity of interest. based on this data the model groups the samples through several probabilistic iterations and thus clusters samples based on there features.


Machine learning is exponentially growing at the moment with big tech giants using machine learning to there everyday operations and processes. Large firms like Google and Microsoft have invested heavily in the research towards machine learning and providing machine learning as a service to the public. Due to advances in the domain of machine learning even a beginner in the field can easily build a model i.e the ease of usage with machine learning libraries has come to a great advantage in reducing production and execution time for constructing a model out of the data. Rapid exploration towards data-science has given a boost to the community in developing simpler and efficient ML libraries for use. Still in order to build a efficient production ready models out of available data one has to spend a considerable amount of time analyzing the features of the data and evaluating the combination of parameters and hyper-parameters for the particular model which they are trying to build. 

\section{Motivation}
In the work-flow of any Machine learning process one has to decide on what features to use from the samples of data, which processing methods to employ and which combination of parameters for the algorithm would be optimal. The time taken for these steps is sometimes greater than the training/learning time of the algorithm itself. 
Analyzing the performance of a classifier over a range of features and hyper-parameters is an exhaustive task, for every algorithm there are parameters  which is utilized during the learning process, several combinations of these parameters produce different outcomes, it can be poor or more efficient compared to other combinations. Manually comparing these combination of parameters is not practical if the algorithm has too many parameters to tune. Several approaches addressed these problems with Exhaustive search of parameter combinations and brute-force techniques. These approaches are expensive in computation since it takes a lot of time to arrive at a optimal combination of parameters for any given algorithm. To address these problems Automatic machine learning which is end-to-end automation of the complete work-flow of machine learning has emerged recently, termed as AutoML\cite{autoML} it helps by providing a automated process for pre-processing methods,selecting features and hyper-parameters based on techniques namely Bayesian optimization and genetic programming. It also provides testing ground for non-machine learning experts to start of with machine learning and for a domain expert gives enough time to concentrate more on the important aspects of the pipeline/work-flow. AutoML can also be used as a out of the box application in building machine learning model.

With the python implementation of the above methods already being implemented, one has to just find the required data-set provide it has the input to these libraries, the entire ML process optimization's will be carried out and a model with optimal configuration will be produced.
In order to understand which method is efficient we need to employ a evaluation for the outcome and describe the performance statistically. Here we will asses the performance of these two libraries based on there generated models accuracy,f1-score for classification tasks and rmse score for regression tasks. \textbf{[write more on metrics and why u choose accuracy ]}

SMAC\cite{smac-2017} stands for Sequential Model-based Algorithm Configuration, it is a tool for algorithm configuration using Bayesian Optimization and simple racing mechanism this has been employed in Autosklearn\cite{autosklearn} to automate the process of finding optimal cost effective functions. The algorithm optimizes the given function based on the cost specified, the cost can be run-time or number of steps also based on the memory usage and several other criterion's. Detailed explanation of the algorithm will be followed in the upcoming chapters \textbf{[write short lines for genetic programming]}

TPOT




With Autosklearn\footnote{\url{https://automl.github.io/auto-sklearn/stable/}} and TPOT\footnote{\url{https://github.com/EpistasisLab/tpot}} having these methods employed we are interested to find out what these libraries can offer to an expert or a novice. The main aim of this thesis is to evaluate the statistical significance between the results of their respective models which has been generated from the Bayesian and genetic approach and also concluding with which library is efficient in handling the vast search space of parameters. The evaluation would be aided by a web interface where all the experimental results and there statistical significance can be observed by an expert and a novice



In this thesis paper evaluation of  two open-source machine learning libraries called Auto-sklearn\cite{autosklearn} and TPOT\cite{tpot} are considered. The main evaluation criterion being the run time of the respective library along with the accuracy and f1-score for classification tasks and root mean squared error rate for regeression tasks. 
General Requirements to the thesis:

\begin{itemize}
	\item 60 pages of content in this format. Content does not include table of content, lists, appendices etc.
	\item Proper scientific referencing
	\item Introduction and Background should be less than 50\% of the thesis
	\item Images should be readable and in the proper size. 
\end{itemize}


\section{Research Questions}
With the two libraries being the main interest of evaluation and how to take up the evaluation of these libraries the following objective's defines my thesis


R1.\label{point:R1} Performance evaluation of supervised classification experiments using the two machine learning libraries Autosklearn\footnote{\url{https://automl.github.io/auto-sklearn/stable/}} and TPOT\footnote{\url{https://github.com/EpistasisLab/tpot}}

R2.\label{point:R2} Statistical significance test between the two models from the accumulated model's performance measures

R3.\label{point:R3} A web interface for visual representation of the experiments

In the first research question the outcome of the two libraries would be assessed based on the experiments using supervised data-sets. Bayesian optimization and genetic programming search methodology will be utilized to generate models. The obtained model its parameters and hyper-parameters will be saved to the database for further analysis

With the accumulated performance measures from each experiment a statistical significance test will be carried out to understand the distribution among the two outcomes i.e the difference between the outcome of each model with the counterpart

In order to efficiently analyze a set of experiments and to aid re-usability a visual aid would be of great help. The experimental results with all the attributes and the properties gained from the tasks are saved to the database so that it can be analyzed visually. The 3rd research question would tackle this task. A simple web interface for comparison of the model's behaviour will be built to aid further explanations from the data.

\section{Approach}
\textbf{Cite bayesian and genetic papers here}


The work in this thesis involves evaluating the two machine learning libraries Autosklearn\footnote{\url{https://automl.github.io/auto-sklearn/stable/}} and TPOT\footnote{\url{https://github.com/EpistasisLab/tpot}} which are open source ML computation tools developed based on the methodologies of Bayesian Optimization \textbf{cite here} and Genetic Programming \textbf{cite here}. There are two different criterion's of evaluation, First is the performance evaluation of the models generated by the two libraries using classification and regression metrics such as accuracy and rmse scores, second is the statistical significance test of the distribution of the performance scores using spearmanr test available from scipy\footnote{\url{https://www.scipy.org/getting-started.html}} library. finally a web-gui is built using python DASH framework\footnote{\url{https://dash.plot.ly/}} which aids in visual inspection of the different parameters obtained from the models generated.

The experiments are supervised classification and regression tasks, variety of data-sets are used to run the experiments from the Penn Machine Learning Benchmarks\cite{plmb} data-sets which is a open source api providing the curated set of data-sets to easily fetch and perform supervised machine learning tasks. The approach consists of two parts, one is the evaluation of the supervised ML experiments second is the development of web framework for visual analysis

\subsection{Procedure}

\begin{itemize}
    \item Collection of datasets
\begin{itemize}
    \item 20 datasets of classification and regression tasks are collected from the different open source ML data providers one of them being Penn Machine Learning Benchmarks\footnote{\url{https://github.com/EpistasisLab/penn-ml-benchmarks}} 
    \item Each dataset has more than 1000 datapoints/instances 
    \item Datasets include multiclass,multilabel and binary data
\end{itemize}

    \item Data preprocessing 
    \begin{itemize}
        \item A small window of data preprocessing is done on the acquired data-sets for checking null values and encoding issues, since the two libraries tackle missing values within the process and the data-sets which are acquired are already in the stable state except for few which needs data preprocessing.
    \end{itemize}
    
    \item Running experiments
    \begin{itemize}
        \item The default settings of the libraries will be used for the experiments for fair performance comparison
    \end{itemize}
    
    \item Curating the results
    \begin{itemize}
        \item Each tool-kit's outcome will be saved in the database such as its accuracy and rmse score together with the gained model parameters and corresponding hyper-parameters
    \end{itemize}
    
    \item Statistical significance test
    \begin{itemize}
        \item The generated models from autosklearn and tpot will be analyzed for there distribution of performance scores on a simple hypothesis
    \end{itemize}





\end{itemize}
\section{Structure of the Thesis}



\section{Example citation \& symbol reference}\label{sec:citation}
For symbols look at \cite{latex_symbols_2017}.


\section{Example reference}
Example reference: Look at chapter~\ref{chap:introduction}, for sections, look at section~\ref{sec:citation}.

\section{Example image}

\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{uni-logo}
	\caption{Meaningful caption for this image}
	\label{fig:uniLogo}
\end{figure}

Example figure reference: Look at Figure~\ref{fig:uniLogo} to see an image. It can be \texttt{jpg}, \texttt{png}, or best: \texttt{pdf} (if vector graphic).

\section{Example table}

\begin{table}
	\centering
	\begin{tabular}{lr}
		First column & Number column \\
		\hline
		Accuracy & 0.532 \\
		F1 score & 0.87
	\end{tabular}
	\caption{Meaningful caption for this table}
	\label{tab:result}
\end{table}

Table~\ref{tab:result} shows a simple table\footnote{Check \url{https://en.wikibooks.org/wiki/LaTeX/Tables} on syntax}